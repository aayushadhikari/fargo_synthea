{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df3e48d",
   "metadata": {},
   "source": [
    "# Privacy-Preserving RAG: Clinical Assistant with Tool Calling\n",
    "\n",
    "This notebook implements a clinical assistant powered by OpenAI's O3 model that can answer patient-specific questions using structured data while preserving privacy through local de-identification.\n",
    "\n",
    "## System Overview\n",
    "- **OpenAI O3 Agent**: Acts as orchestrator and QA engine\n",
    "- **Tool Functions**: Retrieve patient data from various sources\n",
    "- **Local De-identifier**: Removes PHI before sending to OpenAI\n",
    "- **Privacy-Safe Responses**: Clinically informed answers without compromising privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3962aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def generate_note_auto(table_name, patient_id):\n",
    "    \"\"\"\n",
    "    Reads the generated *_notes.csv file for the given table and returns \n",
    "    the first clinical note found for the provided patient_id.\n",
    "\n",
    "    Parameters:\n",
    "    - table_name: str (e.g., \"observations\", \"medications\")\n",
    "    - patient_id: str (the patient_id to search for)\n",
    "\n",
    "    Returns:\n",
    "    - str: the clinical note or a message if not found\n",
    "    \"\"\"\n",
    "    notes_file = os.path.join(\"data\", f\"{table_name}_notes.csv\")\n",
    "\n",
    "    if not os.path.exists(notes_file):\n",
    "        return f\"Note file not found: {notes_file}\"\n",
    "\n",
    "    df = pd.read_csv(notes_file)\n",
    "    \n",
    "    # Normalize column names just in case\n",
    "    df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "    if \"patient_id\" not in df.columns or \"clinical_note\" not in df.columns:\n",
    "        return \"Expected columns not found in the CSV.\"\n",
    "\n",
    "    matching_notes = df[df[\"patient_id\"] == patient_id]\n",
    "\n",
    "    if matching_notes.empty:\n",
    "        return f\"No note found for patient_id: {patient_id}\"\n",
    "\n",
    "    return matching_notes.iloc[0][\"clinical_note\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "978f1157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (1.98.0)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install essential packages\n",
    "# Run this cell first to install core dependencies\n",
    "\n",
    "!pip install openai python-dotenv pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3be14cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "üìÖ Current date: 2025-08-06 22:05:22\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "from datetime import datetime, date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# OpenAI imports\n",
    "from openai import OpenAI\n",
    "\n",
    "# Environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üìÖ Current date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3e7fba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client initialized successfully!\n",
      "ü§ñ Model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# OpenAI Configuration\n",
    "class ClinicalAssistantConfig:\n",
    "    \"\"\"Configuration for the Clinical Assistant\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # OpenAI API configuration\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            print(\"‚ö†Ô∏è  Warning: OPENAI_API_KEY not found in environment variables\")\n",
    "            print(\"üí° Please set your OpenAI API key in a .env file or environment variable\")\n",
    "        \n",
    "        # Model configuration - using GPT-4o-mini for now (O3 models may not be available yet)\n",
    "        self.model = \"gpt-4o-mini\"  # Using GPT-4o-mini until O3 is available\n",
    "        self.max_completion_tokens = 4000  # Use max_completion_tokens for newer models\n",
    "        self.temperature = 0.1  # Low temperature for clinical accuracy\n",
    "        \n",
    "        # Tool calling configuration\n",
    "        self.max_tool_calls = 5\n",
    "        self.parallel_tool_calls = True\n",
    "\n",
    "# Initialize configuration\n",
    "config = ClinicalAssistantConfig()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "if config.api_key:\n",
    "    client = OpenAI(api_key=config.api_key)\n",
    "    print(\"‚úÖ OpenAI client initialized successfully!\")\n",
    "    print(f\"ü§ñ Model: {config.model}\")\n",
    "else:\n",
    "    client = None\n",
    "    print(\"‚ùå OpenAI client not initialized - API key required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e82a446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tool function definitions created!\n",
      "üîß Available tools: 8\n",
      "   - get_patient_observations: Retrieve laboratory test results and clinical observations for a patient\n",
      "   - get_patient_conditions: Retrieve patient diagnosis information, medical conditions, and medical history\n",
      "   - get_patient_medications: Retrieve current and past medications for a patient\n",
      "   - get_patient_careplans: Retrieve care plans and treatment plans for a patient\n",
      "   - get_patient_procedures: Retrieve medical procedures and interventions performed on a patient\n",
      "   - get_patient_imaging_studies: Retrieve imaging studies and radiology reports for a patient\n",
      "   - get_patient_immunizations: Retrieve vaccination history and immunization records for a patient\n",
      "   - get_patient_allergies: Retrieve allergy information and adverse reactions for a patient\n"
     ]
    }
   ],
   "source": [
    "# Tool Function Definitions for OpenAI Function Calling\n",
    "# These will be used by the O3 model to understand available tools\n",
    "\n",
    "TOOL_DEFINITIONS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_patient_observations\",\n",
    "            \"description\": \"Retrieve laboratory test results and clinical observations for a patient\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"patient_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Unique patient identifier\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"patient_id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_patient_conditions\",\n",
    "            \"description\": \"Retrieve patient diagnosis information, medical conditions, and medical history\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"patient_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Unique patient identifier\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"patient_id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_patient_medications\",\n",
    "            \"description\": \"Retrieve current and past medications for a patient\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"patient_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Unique patient identifier\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"patient_id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_patient_careplans\",\n",
    "            \"description\": \"Retrieve care plans and treatment plans for a patient\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"patient_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Unique patient identifier\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"patient_id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_patient_procedures\",\n",
    "            \"description\": \"Retrieve medical procedures and interventions performed on a patient\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"patient_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Unique patient identifier\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"patient_id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_patient_imaging_studies\",\n",
    "            \"description\": \"Retrieve imaging studies and radiology reports for a patient\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"patient_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Unique patient identifier\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"patient_id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_patient_immunizations\",\n",
    "            \"description\": \"Retrieve vaccination history and immunization records for a patient\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"patient_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Unique patient identifier\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"patient_id\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_patient_allergies\",\n",
    "            \"description\": \"Retrieve allergy information and adverse reactions for a patient\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"patient_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Unique patient identifier\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"patient_id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Tool function definitions created!\")\n",
    "print(f\"üîß Available tools: {len(TOOL_DEFINITIONS)}\")\n",
    "for tool in TOOL_DEFINITIONS:\n",
    "    print(f\"   - {tool['function']['name']}: {tool['function']['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b68b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gated model login with Hugging Face CLI\n",
    "# Make sure you have the Hugging Face CLI installed and authenticated\n",
    "!pip install huggingface_hub\n",
    "!pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d493c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "llama_model_load_from_file_impl: using device Metal (Apple M4 Max) - 49151 MiB free\n",
      "llama_model_loader: loaded meta data with 39 key-value pairs and 444 tensors from /Users/aayush/.cache/huggingface/hub/models--google--gemma-3-4b-it-qat-q4_0-gguf/snapshots/15f73f5eee9c28f53afefef5723e29680c2fc78a/./gemma-3-4b-it-q4_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gemma3\n",
      "llama_model_loader: - kv   1:                      gemma3.context_length u32              = 131072\n",
      "llama_model_loader: - kv   2:                         gemma3.block_count u32              = 34\n",
      "llama_model_loader: - kv   3:                    gemma3.embedding_length u32              = 2560\n",
      "llama_model_loader: - kv   4:                 gemma3.feed_forward_length u32              = 10240\n",
      "llama_model_loader: - kv   5:                gemma3.attention.head_count u32              = 8\n",
      "llama_model_loader: - kv   6:             gemma3.attention.head_count_kv u32              = 4\n",
      "llama_model_loader: - kv   7:                gemma3.attention.key_length u32              = 256\n",
      "llama_model_loader: - kv   8:              gemma3.attention.value_length u32              = 256\n",
      "llama_model_loader: - kv   9:    gemma3.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                   gemma3.rope.scaling.type str              = linear\n",
      "llama_model_loader: - kv  11:                 gemma3.rope.scaling.factor f32              = 8.000000\n",
      "llama_model_loader: - kv  12:                      gemma3.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  13:            gemma3.attention.sliding_window u32              = 1024\n",
      "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 2\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 3\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.tokens arr[str,262144]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.scores arr[f32,262144]  = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,262144]  = [3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  23:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {{ bos_token }} {%- if messages[0]['r...\n",
      "llama_model_loader: - kv  25:                 gemma3.mm.tokens_per_image u32              = 256\n",
      "llama_model_loader: - kv  26:         gemma3.vision.attention.head_count u32              = 16\n",
      "llama_model_loader: - kv  27: gemma3.vision.attention.layer_norm_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  28:                  gemma3.vision.block_count u32              = 27\n",
      "llama_model_loader: - kv  29:             gemma3.vision.embedding_length u32              = 1152\n",
      "llama_model_loader: - kv  30:          gemma3.vision.feed_forward_length u32              = 4304\n",
      "llama_model_loader: - kv  31:                   gemma3.vision.image_size u32              = 896\n",
      "llama_model_loader: - kv  32:                 gemma3.vision.num_channels u32              = 3\n",
      "llama_model_loader: - kv  33:                   gemma3.vision.patch_size u32              = 14\n",
      "llama_model_loader: - kv  34:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  35:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  36:           tokenizer.ggml.add_padding_token bool             = false\n",
      "llama_model_loader: - kv  37:           tokenizer.ggml.add_unknown_token bool             = false\n",
      "llama_model_loader: - kv  38:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - type  f32:  205 tensors\n",
      "llama_model_loader: - type  f16:    1 tensors\n",
      "llama_model_loader: - type q4_0:  238 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_0\n",
      "print_info: file size   = 2.93 GiB (6.49 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token: 255999 '<start_of_image>' is not marked as EOG\n",
      "load: control token:    105 '<start_of_turn>' is not marked as EOG\n",
      "load: control token:      2 '<bos>' is not marked as EOG\n",
      "load: control token: 256000 '<end_of_image>' is not marked as EOG\n",
      "load: control token:      1 '<eos>' is not marked as EOG\n",
      "load: control token:      0 '<pad>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 8\n",
      "load: token to piece cache size = 1.9446 MB\n",
      "print_info: arch             = gemma3\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 131072\n",
      "print_info: n_embd           = 2560\n",
      "print_info: n_layer          = 34\n",
      "print_info: n_head           = 8\n",
      "print_info: n_head_kv        = 4\n",
      "print_info: n_rot            = 256\n",
      "print_info: n_swa            = 1024\n",
      "print_info: is_swa_any       = 1\n",
      "print_info: n_embd_head_k    = 256\n",
      "print_info: n_embd_head_v    = 256\n",
      "print_info: n_gqa            = 2\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-06\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 6.2e-02\n",
      "print_info: n_ff             = 10240\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 2\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 0.125\n",
      "print_info: n_ctx_orig_yarn  = 131072\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 4B\n",
      "print_info: model params     = 3.88 B\n",
      "print_info: general.name     = n/a\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 262144\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 2 '<bos>'\n",
      "print_info: EOS token        = 1 '<eos>'\n",
      "print_info: EOT token        = 106 '<end_of_turn>'\n",
      "print_info: UNK token        = 3 '<unk>'\n",
      "print_info: PAD token        = 0 '<pad>'\n",
      "print_info: LF token         = 248 '<0x0A>'\n",
      "print_info: EOG token        = 1 '<eos>'\n",
      "print_info: EOG token        = 106 '<end_of_turn>'\n",
      "print_info: max token length = 93\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer   1 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer   2 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer   3 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer   4 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer   5 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer   7 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer   8 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer   9 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  10 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  11 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  13 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  14 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  15 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  16 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  17 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  19 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  20 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  21 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  22 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  23 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  25 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  26 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  27 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  28 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  29 assigned to device CPU, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  31 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  32 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  33 assigned to device CPU, is_swa = 1\n",
      "load_tensors: layer  34 assigned to device CPU, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (f16) (and 206 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "load_tensors: offloading 0 repeating layers to GPU\n",
      "load_tensors: offloaded 0/35 layers to GPU\n",
      "load_tensors:   CPU_Mapped model buffer size =  3002.65 MiB\n",
      "load_tensors:   CPU_REPACK model buffer size =  1721.25 MiB\n",
      ".repack: repack tensor blk.0.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.0.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.0.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.0.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.0.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.0.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.0.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.1.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.1.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.1.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.1.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.1.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.1.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.1.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.2.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.2.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.2.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.2.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.2.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.2.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.2.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.3.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.3.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.3.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.3.attn_output.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.3.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.3.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.3.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.4.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.4.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.4.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.4.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.4.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.4.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.4.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.5.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.5.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.5.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.5.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.5.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.5.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.5.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.6.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.6.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.6.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.6.attn_output.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.6.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.6.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.6.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.7.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.7.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.7.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.7.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.7.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.7.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.7.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.8.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.8.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.8.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.8.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.8.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.8.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.8.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.9.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.9.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.9.attn_v.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.9.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.9.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.9.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.9.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.10.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.10.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.10.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.10.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.10.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.10.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.10.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.11.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.11.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.11.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.11.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.11.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.11.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.11.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.12.attn_q.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.12.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.12.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.12.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.12.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.12.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.12.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.13.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.13.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.13.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.13.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.13.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.13.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.13.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.14.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.14.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.14.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.14.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.14.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.14.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.14.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.15.attn_q.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.15.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.15.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.15.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.15.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.15.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.15.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.16.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.16.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.16.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.16.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.16.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.16.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.16.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.17.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.17.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.17.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.17.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.17.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.17.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.17.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.18.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.18.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.18.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.18.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.18.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.18.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.18.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.19.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.19.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.19.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.19.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.19.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.19.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.19.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.20.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.20.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.20.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.20.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.20.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.20.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.20.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.21.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.21.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.21.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.21.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.21.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.21.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.21.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.22.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.22.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.22.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.22.attn_output.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.22.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.22.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.22.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.23.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.23.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.23.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.23.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.23.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.23.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.23.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.24.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.24.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.24.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.24.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.24.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.24.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.24.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.25.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.25.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.25.attn_v.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.25.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.25.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.25.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.25.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.26.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.26.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.26.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.26.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.26.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.26.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.26.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.27.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.27.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.27.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.27.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.27.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.27.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.27.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.28.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.28.attn_k.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.28.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.28.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.28.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.28.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.28.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.29.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.29.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.29.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.29.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.29.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.29.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.29.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.30.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.30.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.30.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.30.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.30.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.30.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.30.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.31.attn_q.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.31.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.31.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.31.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.31.ffn_gate.weight with q4_0_4x8\n",
      "repack: repack tensor blk.31.ffn_up.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.31.ffn_down.weight with q4_0_4x8\n",
      "repack: repack tensor blk.32.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.32.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.32.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.32.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.32.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.32.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.32.ffn_down.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.33.attn_q.weight with q4_0_4x8\n",
      "repack: repack tensor blk.33.attn_k.weight with q4_0_4x8\n",
      "repack: repack tensor blk.33.attn_v.weight with q4_0_4x8\n",
      "repack: repack tensor blk.33.attn_output.weight with q4_0_4x8\n",
      "repack: repack tensor blk.33.ffn_gate.weight with q4_0_4x8\n",
      ".repack: repack tensor blk.33.ffn_up.weight with q4_0_4x8\n",
      "repack: repack tensor blk.33.ffn_down.weight with q4_0_4x8\n",
      ".\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 2048\n",
      "llama_context: n_ctx_per_seq = 2048\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: freq_base     = 1000000.0\n",
      "llama_context: freq_scale    = 0.125\n",
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M4 Max\n",
      "ggml_metal_init: picking default device: Apple M4 Max\n",
      "ggml_metal_load_library: using embedded metal library\n",
      "Exception ignored on calling ctypes callback function: <function llama_log_callback at 0x30984b760>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/health-hw7/lib/python3.10/site-packages/llama_cpp/_logger.py\", line 29, in llama_log_callback\n",
      "    @llama_cpp.llama_log_callback\n",
      "KeyboardInterrupt: \n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 51539.61 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x142c6bf50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                                0x142c66480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x308829130 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                                0x3088289e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x308829b80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                                0x142c6d1d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x30882a1e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                                0x30882b070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x142c6c9f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x132f7c460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x132f7cb20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x132f7d3e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x30882b330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x142c6d9f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x30882bb80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x1120342b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x112036590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x112037730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x30882c5d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x142c6e020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf                               0x112036880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf_4                             0x1120384d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x30882cf30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x30882d7f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x142c6ea50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x142c6f460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x30882e5f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_abs                                    0x10653bfe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sgn                                    0x10657ffe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_step                                   0x106580650 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardswish                              0x106580b90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardsigmoid                            0x30eca9950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_exp                                    0x142c6fc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x142c70a60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x30eca8e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x30ecaae30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x142c71f90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x30ecaa710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x30ecabc20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x106580e50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x106581110 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x30ecab400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x1065813d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x30882eac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x132f7df00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x30ecabff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x30ecac440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x142c701c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x30ecac740 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x30882f0d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x30ecad370 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x132f7bea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x308830040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x142c71750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x142c72c10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x142c73340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x142c739f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x142c74120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x30882f490 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x30ecadab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x30ecae9b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f32                           0x112038be0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f16                           0x142c72680 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_set_rows_q8_0                          0x132f7e2d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_0                          0x132f7f0f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_1                          0x132f7e7c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_0                          0x106581690 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_1                          0x112039e50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_iq4_nl                        0x132f7fea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x308830f30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_l2_norm                                0x3088306c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x30ecae320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x30ecaf880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x132f7f6c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x132f80b90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32_group                     0x132f81250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv6_f32                          0x106581950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv7_f32                          0x308831e10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x30ecb0000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32_c4                      0x106581c10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x142c74fa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_c4                      0x30ecaef40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x142c753d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x308832520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x30ecb03f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x30ecb06b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x30ecb1be0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x1065823e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x112039370 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x132f81ad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x30ecb0ca0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x142c75690 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x106582b80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x142c76730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x308833260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x30ecb2030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x11203ab30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x308833550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x30ecb3000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x1065832e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x30ecb3940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x308833810 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x142c75ad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x132e04080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x309a49e10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x132e04340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x1428c3a90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x132e04b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x1138bd850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x1428c4320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x309a4a1a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x142e055f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x1139c5830 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x309a4a460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x1139c5af0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x1139c5db0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x309a4a850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x1139c6070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x308674070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x1139c6330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x132e04600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x308674330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x1428c4a20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x1139c65f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x309a4b020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x1428c5240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x132e05240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x142e058b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x1139c68b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x309a4ab10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x132e05a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x132e05500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x1139c6b70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x1138fde40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x1428c5600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x1139c6e30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x1139c70f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x132e05cf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x3086745f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x11203a240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x1138fe100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x308675860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x309a4b6e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x308675b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x1428c08c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x1138fe3c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x1428c5b80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x1428c5e40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x132e06640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x308675de0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x3086760a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x1139c73b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x1428c6a60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x1139c7670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x132e06d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x309a4c710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x309a4ce80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x1428c7000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x132e06fc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x1428c72c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x1138fe680 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x132e07c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x309a4d900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x309a4e0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x309a4e800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x309a4ef30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x308676360 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x308676620 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x1138fe940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x3086768e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x1138fec00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x309a4f5c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x1139c7930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x308676ba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x308676e60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x1428c7720 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x308677120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x1428c7b90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x1138feec0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x1428c82c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x1428c9920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x132e073d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x3086773e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x132e08410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x1138ff180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x1428ca0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map0_f16                     0x309a4fbb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map1_f32                     0x1139c7bf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f16                      0x1139c7eb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f16                      0x1138ff440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f16                     0x1139c8170 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f16                     0x3086776a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f16                     0x308677960 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f16                     0x1428ca7e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f16                     0x308a2aad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f16                     0x308a2c130 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f16                     0x1138ff700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f16                     0x309a504a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f16                     0x1139c8430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f16                     0x132e08870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f16                  0x308a2cea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f16                   0x308a2c810 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f16                  0x1139c86f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f16                    0x1139c89b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f16                    0x1139c8c70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f16                    0x1138ff9c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f16                    0x1138ffc80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f16                   0x309f04080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f16                   0x308a2d7e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x309f04340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x308677eb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f32                         0x308678170 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f16                         0x308678430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f32                        0x309f04600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f16                        0x1139c8f30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x1139c92f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x3086786f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x308a2e060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x309f048c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x308a2f0f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x308a2e900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x308a2f5e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x309f04b80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x308a30570 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x309a50bf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x1428cb040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x1139c95b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x309f04e40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x309f05100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x1139c9e70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x309f05770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x309f05dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x1139ca2b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x309f06180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x3086789b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x309f06500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h192                0x309f067c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk192_hv128         0x309a51720 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x1139cb8e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk576_hv512         0x309f07200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x308a31270 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x1428cbe50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x308a30ca0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x1428cc6b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x1428cce10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h192               0x309f076a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk192_hv128        0x308678c70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x309a51c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk576_hv512        0x308678f30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x309f082e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x1139c9870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x1139ca9e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x308a32060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x309a52b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h192               0x309f08e10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk192_hv128        0x309a52e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x3086791f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk576_hv512        0x1139cbc70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x3086794b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x308679770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x309a539c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x308833ad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x132f823f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h192               0x132f83140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk192_hv128        0x106583f40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x11203a6a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk576_hv512        0x132f834d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x30ecb25b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x1065846a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x11203b290 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x132f838e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x11203ba40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h192               0x132f83cf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk192_hv128        0x11203d880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x3088352f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk576_hv512        0x132f841e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x11203d290 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x106584a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x11203dc10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x30ecb4660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x142c771c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h192               0x1065855c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk192_hv128        0x308833f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x11203df30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk576_hv512        0x132f85b10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h64             0x30ecb4d90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h64            0x106585c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h64            0x3088361f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h64            0x30ecb5df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h64            0x1065863a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h64            0x3088369e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h96             0x30ecb6180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h96            0x11203f0d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h96            0x308835e70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h96            0x308679a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h96            0x308679cf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h96            0x1428cd1a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x30ecb68a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x30ecb6c20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x30ecb77b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x142c77480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x132f86510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x11203e250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h192            0x3088379e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h192           0x142c78650 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h192           0x132f86d40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h192           0x106586720 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h192           0x30ecb7b40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h192           0x308836630 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk192_hv128      0x3088386a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk192_hv128      0x308838a50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk192_hv128      0x132f875d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk192_hv128      0x308838ea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk192_hv128      0x132f868a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk192_hv128      0x308839820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x142c77a90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x142c79590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x30ecb8660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x308839c90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x11203f8c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x132f88130 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk576_hv512      0x112040ca0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk576_hv512      0x142c78f90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk576_hv512      0x132f886d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk576_hv512      0x142c78ac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk576_hv512      0x1120406d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk576_hv512      0x132f88b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x106587180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x30ecb8060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x132f88f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x30ecb8a10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x106587940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x30883aba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x30883b530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x30ecb9380 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x30ecb9a80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x132f89ee0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x30ecb8cd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x30883af30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f32                           0x142c7a590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f16                           0x142c7ac30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f32                           0x30ecba750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f16                           0x142c7b2f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f32                           0x112041690 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f16                           0x112041030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f32                           0x142c7ba80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f16                           0x30883c320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f32                           0x30883c9d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f16                           0x132f8a310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x30ecb9f80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x30ecbae40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x30ecbbae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x132f8a6a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x30ecbc350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_neg                                    0x30883bcc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_reglu                                  0x30ecbce30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu                                  0x30ecbd7e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_swiglu                                 0x30883d120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_erf                              0x30ecbd180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_quick                            0x30883d3e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x30883e7c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mean                                   0x132f8ae40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x132f8bc80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x132f8c340 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x132f8b3e0 | th_max = 1024 | th_width =   32\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     1.00 MiB\n",
      "create_memory: n_ctx = 2048 (padded)\n",
      "llama_kv_cache_unified_iswa: using full-size SWA cache (ref: https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)\n",
      "llama_kv_cache_unified_iswa: creating non-SWA KV cache, size = 2048 cells\n",
      "llama_kv_cache_unified: layer   0: skipped\n",
      "llama_kv_cache_unified: layer   1: skipped\n",
      "llama_kv_cache_unified: layer   2: skipped\n",
      "llama_kv_cache_unified: layer   3: skipped\n",
      "llama_kv_cache_unified: layer   4: skipped\n",
      "llama_kv_cache_unified: layer   5: dev = CPU\n",
      "llama_kv_cache_unified: layer   6: skipped\n",
      "llama_kv_cache_unified: layer   7: skipped\n",
      "llama_kv_cache_unified: layer   8: skipped\n",
      "llama_kv_cache_unified: layer   9: skipped\n",
      "llama_kv_cache_unified: layer  10: skipped\n",
      "llama_kv_cache_unified: layer  11: dev = CPU\n",
      "llama_kv_cache_unified: layer  12: skipped\n",
      "llama_kv_cache_unified: layer  13: skipped\n",
      "llama_kv_cache_unified: layer  14: skipped\n",
      "llama_kv_cache_unified: layer  15: skipped\n",
      "llama_kv_cache_unified: layer  16: skipped\n",
      "llama_kv_cache_unified: layer  17: dev = CPU\n",
      "llama_kv_cache_unified: layer  18: skipped\n",
      "llama_kv_cache_unified: layer  19: skipped\n",
      "llama_kv_cache_unified: layer  20: skipped\n",
      "llama_kv_cache_unified: layer  21: skipped\n",
      "llama_kv_cache_unified: layer  22: skipped\n",
      "llama_kv_cache_unified: layer  23: dev = CPU\n",
      "llama_kv_cache_unified: layer  24: skipped\n",
      "llama_kv_cache_unified: layer  25: skipped\n",
      "llama_kv_cache_unified: layer  26: skipped\n",
      "llama_kv_cache_unified: layer  27: skipped\n",
      "llama_kv_cache_unified: layer  28: skipped\n",
      "llama_kv_cache_unified: layer  29: dev = CPU\n",
      "llama_kv_cache_unified: layer  30: skipped\n",
      "llama_kv_cache_unified: layer  31: skipped\n",
      "llama_kv_cache_unified: layer  32: skipped\n",
      "llama_kv_cache_unified: layer  33: skipped\n",
      "llama_kv_cache_unified:        CPU KV buffer size =    40.00 MiB\n",
      "llama_kv_cache_unified: size =   40.00 MiB (  2048 cells,   5 layers,  1 seqs), K (f16):   20.00 MiB, V (f16):   20.00 MiB\n",
      "llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\n",
      "llama_kv_cache_unified_iswa: creating     SWA KV cache, size = 2048 cells\n",
      "llama_kv_cache_unified: layer   0: dev = CPU\n",
      "llama_kv_cache_unified: layer   1: dev = CPU\n",
      "llama_kv_cache_unified: layer   2: dev = CPU\n",
      "llama_kv_cache_unified: layer   3: dev = CPU\n",
      "llama_kv_cache_unified: layer   4: dev = CPU\n",
      "llama_kv_cache_unified: layer   5: skipped\n",
      "llama_kv_cache_unified: layer   6: dev = CPU\n",
      "llama_kv_cache_unified: layer   7: dev = CPU\n",
      "llama_kv_cache_unified: layer   8: dev = CPU\n",
      "llama_kv_cache_unified: layer   9: dev = CPU\n",
      "llama_kv_cache_unified: layer  10: dev = CPU\n",
      "llama_kv_cache_unified: layer  11: skipped\n",
      "llama_kv_cache_unified: layer  12: dev = CPU\n",
      "llama_kv_cache_unified: layer  13: dev = CPU\n",
      "llama_kv_cache_unified: layer  14: dev = CPU\n",
      "llama_kv_cache_unified: layer  15: dev = CPU\n",
      "llama_kv_cache_unified: layer  16: dev = CPU\n",
      "llama_kv_cache_unified: layer  17: skipped\n",
      "llama_kv_cache_unified: layer  18: dev = CPU\n",
      "llama_kv_cache_unified: layer  19: dev = CPU\n",
      "llama_kv_cache_unified: layer  20: dev = CPU\n",
      "llama_kv_cache_unified: layer  21: dev = CPU\n",
      "llama_kv_cache_unified: layer  22: dev = CPU\n",
      "llama_kv_cache_unified: layer  23: skipped\n",
      "llama_kv_cache_unified: layer  24: dev = CPU\n",
      "llama_kv_cache_unified: layer  25: dev = CPU\n",
      "llama_kv_cache_unified: layer  26: dev = CPU\n",
      "llama_kv_cache_unified: layer  27: dev = CPU\n",
      "llama_kv_cache_unified: layer  28: dev = CPU\n",
      "llama_kv_cache_unified: layer  29: skipped\n",
      "llama_kv_cache_unified: layer  30: dev = CPU\n",
      "llama_kv_cache_unified: layer  31: dev = CPU\n",
      "llama_kv_cache_unified: layer  32: dev = CPU\n",
      "llama_kv_cache_unified: layer  33: dev = CPU\n",
      "llama_kv_cache_unified:        CPU KV buffer size =   232.00 MiB\n",
      "llama_kv_cache_unified: size =  232.00 MiB (  2048 cells,  29 layers,  1 seqs), K (f16):  116.00 MiB, V (f16):  116.00 MiB\n",
      "llama_kv_cache_unified: LLAMA_SET_ROWS=0, using old ggml_cpy() method for backwards compatibility\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 3\n",
      "llama_context: max_nodes = 65536\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:        CPU compute buffer size =   522.00 MiB\n",
      "llama_context: graph nodes  = 1537\n",
      "llama_context: graph splits = 70 (with bs=512), 1 (with bs=1)\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | SME = 1 | ACCELERATE = 1 | REPACK = 1 | \n",
      "Model metadata: {'tokenizer.ggml.pre': 'default', 'tokenizer.ggml.add_padding_token': 'false', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'gemma3.vision.num_channels': '3', 'gemma3.vision.image_size': '896', 'gemma3.vision.attention.head_count': '16', 'gemma3.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.bos_token_id': '2', 'gemma3.mm.tokens_per_image': '256', 'tokenizer.ggml.add_unknown_token': 'false', 'tokenizer.chat_template': '{{ bos_token }} {%- if messages[0][\\'role\\'] == \\'system\\' -%} {%- if messages[0][\\'content\\'] is string -%} {%- set first_user_prefix = messages[0][\\'content\\'] + \\'\\\\n\\' -%} {%- else -%} {%- set first_user_prefix = messages[0][\\'content\\'][0][\\'text\\'] + \\'\\\\n\\' -%} {%- endif -%} {%- set loop_messages = messages[1:] -%} {%- else -%} {%- set first_user_prefix = \"\" -%} {%- set loop_messages = messages -%} {%- endif -%} {%- for message in loop_messages -%} {%- if (message[\\'role\\'] == \\'user\\') != (loop.index0 % 2 == 0) -%} {{ raise_exception(\"Conversation roles must alternate user/assistant/user/assistant/...\") }} {%- endif -%} {%- if (message[\\'role\\'] == \\'assistant\\') -%} {%- set role = \"model\" -%} {%- else -%} {%- set role = message[\\'role\\'] -%} {%- endif -%} {{ \\'<start_of_turn>\\' + role + \\'\\\\n\\' + (first_user_prefix if loop.first else \"\") }} {%- if message[\\'content\\'] is string -%} {{ message[\\'content\\'] | trim }} {%- elif message[\\'content\\'] is iterable -%} {%- for item in message[\\'content\\'] -%} {%- if item[\\'type\\'] == \\'image\\' -%} {{ \\'<start_of_image>\\' }} {%- elif item[\\'type\\'] == \\'text\\' -%} {{ item[\\'text\\'] | trim }} {%- endif -%} {%- endfor -%} {%- else -%} {{ raise_exception(\"Invalid content type\") }} {%- endif -%} {{ \\'<end_of_turn>\\\\n\\' }} {%- endfor -%} {%- if add_generation_prompt -%} {{\\'<start_of_turn>model\\\\n\\'}} {%- endif -%}', 'general.quantization_version': '2', 'gemma3.attention.head_count_kv': '4', 'tokenizer.ggml.padding_token_id': '0', 'gemma3.attention.sliding_window': '1024', 'gemma3.rope.freq_base': '1000000.000000', 'gemma3.rope.scaling.factor': '8.000000', 'tokenizer.ggml.model': 'llama', 'gemma3.context_length': '131072', 'gemma3.vision.feed_forward_length': '4304', 'gemma3.rope.scaling.type': 'linear', 'gemma3.vision.attention.layer_norm_epsilon': '0.000001', 'tokenizer.ggml.unknown_token_id': '3', 'gemma3.embedding_length': '2560', 'gemma3.vision.block_count': '27', 'gemma3.attention.value_length': '256', 'gemma3.vision.embedding_length': '1152', 'general.file_type': '2', 'gemma3.vision.patch_size': '14', 'gemma3.block_count': '34', 'gemma3.attention.head_count': '8', 'gemma3.attention.key_length': '256', 'tokenizer.ggml.eos_token_id': '1', 'gemma3.feed_forward_length': '10240', 'general.architecture': 'gemma3'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{ bos_token }} {%- if messages[0]['role'] == 'system' -%} {%- if messages[0]['content'] is string -%} {%- set first_user_prefix = messages[0]['content'] + '\\n' -%} {%- else -%} {%- set first_user_prefix = messages[0]['content'][0]['text'] + '\\n' -%} {%- endif -%} {%- set loop_messages = messages[1:] -%} {%- else -%} {%- set first_user_prefix = \"\" -%} {%- set loop_messages = messages -%} {%- endif -%} {%- for message in loop_messages -%} {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%} {{ raise_exception(\"Conversation roles must alternate user/assistant/user/assistant/...\") }} {%- endif -%} {%- if (message['role'] == 'assistant') -%} {%- set role = \"model\" -%} {%- else -%} {%- set role = message['role'] -%} {%- endif -%} {{ '<start_of_turn>' + role + '\\n' + (first_user_prefix if loop.first else \"\") }} {%- if message['content'] is string -%} {{ message['content'] | trim }} {%- elif message['content'] is iterable -%} {%- for item in message['content'] -%} {%- if item['type'] == 'image' -%} {{ '<start_of_image>' }} {%- elif item['type'] == 'text' -%} {{ item['text'] | trim }} {%- endif -%} {%- endfor -%} {%- else -%} {{ raise_exception(\"Invalid content type\") }} {%- endif -%} {{ '<end_of_turn>\\n' }} {%- endfor -%} {%- if add_generation_prompt -%} {{'<start_of_turn>model\\n'}} {%- endif -%}\n",
      "Using chat eos_token: <eos>\n",
      "Using chat bos_token: <bos>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# from huggingface_hub import login\n",
    "# login(os.getenv(\"HUGGING_FACE_API_KEY\"))\n",
    "\n",
    "# from llama_cpp import Llama\n",
    "\n",
    "# # Download the model to 'models/gemma-3-4b-it-qat-q4_0.gguf' as per previous steps\n",
    "# llm = Llama.from_pretrained(\n",
    "#     repo_id=\"google/gemma-3-4b-it-qat-q4_0-gguf\",\n",
    "#     filename=\"gemma-3-4b-it-q4_0.gguf\",  # ‚úÖ correct filename\n",
    "#     n_ctx=2048,\n",
    "#     n_threads=8\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab564dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:04<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "BASE_MODEL = \"google/gemma-2b\"\n",
    "LORA_MODEL_PATH = \"./gemma-deid-lora/checkpoint-60\"\n",
    "\n",
    "# Load tokenizer and base model\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Apply LoRA weights\n",
    "model = PeftModel.from_pretrained(base_model, LORA_MODEL_PATH)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def deidentify(user_data: str):\n",
    "    # Combine system prompt and user data\n",
    "    prompt = f\"\"\"\n",
    "        You are a local language model responsible for enforcing HIPAA compliance by identifying and \n",
    "        removing all Protected Health Information (PHI) from clinical text and structured data before \n",
    "        it is passed to an external system. Your task is to remove all 18 identifiers defined under \n",
    "        HIPAA's Safe Harbor rule while preserving the clinical meaning of the data.\n",
    "\n",
    "        Redact all identifiers like names, dates, addresses, SSNs, etc. with placeholder [REDACTED], without summarizing or altering clinical facts.\n",
    "\n",
    "        ---\n",
    "        <data_with_phi>\n",
    "        {user_data}\n",
    "        </data_with_phi>\n",
    "        <data_hipaa_compliant>\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize input\n",
    "    device = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=300,         # ‚¨ÜÔ∏è Allow longer outputs\n",
    "            temperature=0.7,\n",
    "            do_sample=False,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id  # üëà Avoid warnings\n",
    "        )\n",
    "\n",
    "    # Decode and extract only redacted portion\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    if \"<data_hipaa_compliant>\" in decoded:\n",
    "        redacted_part = decoded.split(\"<data_hipaa_compliant>\")[-1]\n",
    "        redacted_part = redacted_part.split(\"</data_hipaa_compliant>\")[0].strip()\n",
    "    else:\n",
    "        redacted_part = decoded[len(prompt):].strip()\n",
    "\n",
    "    print(\"üîí Redaction complete. PHI has been removed from the clinical note.\")\n",
    "    print(f\"üìÑ Redacted note: {redacted_part}\")  # Print first 100 chars for preview\n",
    "    return redacted_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b282f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Clinical Data Tools initialized with all available note types\n",
      "‚úÖ Clinical tools instance created with all available note types!\n",
      "üìã Available note types: observations, conditions, medications, careplans, procedures, imaging_studies, immunizations, allergies\n"
     ]
    }
   ],
   "source": [
    "# Tool Function Implementations (Using generate_notes_for_type)\n",
    "class ClinicalDataTools:\n",
    "    \"\"\"Clinical data retrieval tools for the OpenAI assistant\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.de_identifier = None  # Will be initialized later\n",
    "        print(\"üîß Clinical Data Tools initialized with all available note types\")\n",
    "    \n",
    "    def get_patient_observations(self, patient_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve laboratory test results and clinical observations for a patient\n",
    "        \n",
    "        Args:\n",
    "            patient_id: Unique patient identifier\n",
    "        \"\"\"\n",
    "        return generate_note_auto(\"observations\",patient_id)\n",
    "    \n",
    "    def get_patient_conditions(self, patient_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve patient diagnosis information, medical conditions, and medical history\n",
    "        \n",
    "        Args:\n",
    "            patient_id: Unique patient identifier\n",
    "        \"\"\"\n",
    "        return generate_note_auto(\"conditions\", patient_id)\n",
    "\n",
    "    def get_patient_medications(self, patient_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve current and past medications for a patient\n",
    "        \n",
    "        Args:\n",
    "            patient_id: Unique patient identifier\n",
    "        \"\"\"\n",
    "        return generate_note_auto(\"medications\", patient_id)\n",
    "\n",
    "    def get_patient_careplans(self, patient_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve care plans and treatment plans for a patient\n",
    "        \n",
    "        Args:\n",
    "            patient_id: Unique patient identifier\n",
    "        \"\"\"\n",
    "        return generate_note_auto(\"careplans\", patient_id)\n",
    "\n",
    "    def get_patient_procedures(self, patient_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve medical procedures and interventions performed on a patient\n",
    "        \n",
    "        Args:\n",
    "            patient_id: Unique patient identifier\n",
    "        \"\"\"\n",
    "        return generate_note_auto(\"procedures\", patient_id)\n",
    "\n",
    "    def get_patient_imaging_studies(self, patient_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve imaging studies and radiology reports for a patient\n",
    "        \n",
    "        Args:\n",
    "            patient_id: Unique patient identifier\n",
    "        \"\"\"\n",
    "        return generate_note_auto(\"imaging_studies\", patient_id)\n",
    "\n",
    "    def get_patient_immunizations(self, patient_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve vaccination history and immunization records for a patient\n",
    "        \n",
    "        Args:\n",
    "            patient_id: Unique patient identifier\n",
    "        \"\"\"\n",
    "        return generate_note_auto(\"immunizations\", patient_id)\n",
    "\n",
    "    def get_patient_allergies(self, patient_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Retrieve allergy information and adverse reactions for a patient\n",
    "        \n",
    "        Args:\n",
    "            patient_id: Unique patient identifier\n",
    "        \"\"\"\n",
    "        return generate_note_auto(\"allergies\", patient_id)\n",
    "\n",
    "# Initialize the tools\n",
    "clinical_tools = ClinicalDataTools()\n",
    "print(\"‚úÖ Clinical tools instance created with all available note types!\")\n",
    "print(\"üìã Available note types: observations, conditions, medications, careplans, procedures, imaging_studies, immunizations, allergies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a63381ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Call and Prompt Management Functions\n",
    "def build_system_prompt() -> str:\n",
    "    \"\"\"Build the system prompt for the clinical assistant\"\"\"\n",
    "    return f\"\"\"You are an AI Clinical Reasoning Assistant with expertise in internal medicine. \n",
    "    Analyze clinical data and respond to patient-specific questions using structured reasoning.\n",
    "\n",
    "    Available Tools:\n",
    "    - get_patient_observations(): Laboratory test results and clinical observations\n",
    "    - get_patient_conditions(): Diagnosis history, medical conditions, and medical history\n",
    "    - get_patient_medications(): Current and past medications\n",
    "    - get_patient_careplans(): Care plans and treatment plans\n",
    "    - get_patient_procedures(): Medical procedures and interventions\n",
    "    - get_patient_imaging_studies(): Imaging studies and radiology reports\n",
    "    - get_patient_immunizations(): Vaccination history and immunization records\n",
    "    - get_patient_allergies(): Allergy information and adverse reactions\n",
    "\n",
    "    Clinical Reasoning Framework:\n",
    "    1. Analyze the question to determine needed information\n",
    "    2. Use appropriate tools to gather relevant patient data\n",
    "    3. Synthesize findings from multiple data sources\n",
    "    4. Provide clear, evidence-based responses with clinical reasoning\n",
    "\n",
    "    Rules:\n",
    "    - Use ONLY data provided by tool outputs\n",
    "    - Reference relative timeframes when provided (e.g., \"Day 0\", \"Post-op Day 3\")\n",
    "    - Acknowledge limitations if data is insufficient\n",
    "    - Suggest additional information needed when applicable\n",
    "    - Consider interactions between medications, conditions, and procedures\n",
    "    - Always check for allergies before recommending treatments\n",
    "\n",
    "    Current date: {datetime.now().strftime('%Y-%m-%d')}\n",
    "    \"\"\"\n",
    "\n",
    "def build_messages(query: str, patient_id: str = None) -> List[Dict[str, str]]:\n",
    "    \"\"\"Build messages for the LLM call\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": build_system_prompt()},\n",
    "        {\"role\": \"user\", \"content\": f\"Clinical query: {query}\"}\n",
    "    ]\n",
    "    \n",
    "    if patient_id:\n",
    "        messages[-1][\"content\"] += f\"\\\\nPatient ID: {patient_id}\"\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def call_llm(client: OpenAI, config: ClinicalAssistantConfig, messages: List[Dict[str, str]]):\n",
    "    \"\"\"Make the actual LLM call\"\"\"\n",
    "    return client.chat.completions.create(\n",
    "        model=config.model,\n",
    "        messages=messages,\n",
    "        tools=TOOL_DEFINITIONS,\n",
    "        tool_choice=\"auto\",\n",
    "        max_completion_tokens=config.max_completion_tokens,\n",
    "        temperature=config.temperature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d447c046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Clinical Assistant initialized with all 8 tool functions!\n"
     ]
    }
   ],
   "source": [
    "# Clinical Assistant with Optional De-identification\n",
    "class ClinicalAssistant:\n",
    "    \"\"\"Main clinical assistant that orchestrates OpenAI GPT-4o-mini model with tool calling\"\"\"\n",
    "    \n",
    "    def __init__(self, client: OpenAI, config: ClinicalAssistantConfig, tools: ClinicalDataTools):\n",
    "        self.client = client\n",
    "        self.config = config\n",
    "        self.tools = tools\n",
    "        \n",
    "        # Map function names to actual methods\n",
    "        self.function_map = {\n",
    "            \"get_patient_observations\": self.tools.get_patient_observations,\n",
    "            \"get_patient_conditions\": self.tools.get_patient_conditions,\n",
    "            \"get_patient_medications\": self.tools.get_patient_medications,\n",
    "            \"get_patient_careplans\": self.tools.get_patient_careplans,\n",
    "            \"get_patient_procedures\": self.tools.get_patient_procedures,\n",
    "            \"get_patient_imaging_studies\": self.tools.get_patient_imaging_studies,\n",
    "            \"get_patient_immunizations\": self.tools.get_patient_immunizations,\n",
    "            \"get_patient_allergies\": self.tools.get_patient_allergies\n",
    "        }\n",
    "    \n",
    "    def de_identify_data(self, data: str) -> str:\n",
    "        \"\"\"De-identify text data using the existing deidentify function\"\"\"\n",
    "        try:\n",
    "            return deidentify(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: De-identification failed: {e}\")\n",
    "            return data\n",
    "    \n",
    "    def execute_tool_call(self, function_name: str, arguments: Dict[str, Any], apply_deidentification: bool = False) -> str:\n",
    "        \"\"\"Execute a tool function call with optional de-identification\"\"\"\n",
    "        if function_name not in self.function_map:\n",
    "            return f\"Error: Unknown function: {function_name}\"\n",
    "        print(f\"Executing tool call: {function_name}\")\n",
    "        try:\n",
    "            func = self.function_map[function_name]\n",
    "            raw_result = func(**arguments)\n",
    "            \n",
    "            # Apply de-identification if requested\n",
    "            if apply_deidentification and isinstance(raw_result, str):\n",
    "                return self.de_identify_data(raw_result)\n",
    "            \n",
    "            return raw_result\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error executing {function_name}: {str(e)}\"\n",
    "    \n",
    "    def process_clinical_query(self, query: str, patient_id: str = None, apply_deidentification: bool = False) -> str:\n",
    "        \"\"\"\n",
    "        Process a clinical query using OpenAI GPT-4o-mini with tool calling\n",
    "        \n",
    "        Args:\n",
    "            query: The clinical question to answer\n",
    "            patient_id: Optional patient ID if known\n",
    "            apply_deidentification: Whether to apply de-identification to tool outputs\n",
    "            \n",
    "        Returns:\n",
    "            Clinical assistant response\n",
    "        \"\"\"\n",
    "        if not self.client:\n",
    "            return \"‚ùå OpenAI client not initialized. Please check your API key.\"\n",
    "        \n",
    "        try:\n",
    "            # Get initial response from LLM\n",
    "            messages = build_messages(query, patient_id)\n",
    "            response = call_llm(self.client, self.config, messages)\n",
    "            \n",
    "            # Handle tool calls if any\n",
    "            if response.choices[0].message.tool_calls:\n",
    "                current_messages = messages.copy()\n",
    "                current_messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": response.choices[0].message.content,\n",
    "                    \"tool_calls\": response.choices[0].message.tool_calls\n",
    "                })\n",
    "                \n",
    "                # Process each tool call\n",
    "                for tool_call in response.choices[0].message.tool_calls:\n",
    "                    function_name = tool_call.function.name\n",
    "                    function_args = json.loads(tool_call.function.arguments)\n",
    "                    \n",
    "                    # Execute tool call with optional de-identification\n",
    "                    tool_result = self.execute_tool_call(function_name, function_args, apply_deidentification)\n",
    "                    \n",
    "                    current_messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"content\": tool_result\n",
    "                    })\n",
    "                \n",
    "                # Get final response with tool results\n",
    "                final_response = call_llm(self.client, self.config, current_messages)\n",
    "                return final_response.choices[0].message.content\n",
    "            else:\n",
    "                return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Error processing query: {str(e)}\"\n",
    "\n",
    "# Initialize the clinical assistant\n",
    "if client:\n",
    "    assistant = ClinicalAssistant(client, config, clinical_tools)\n",
    "    print(\"‚úÖ Clinical Assistant initialized with all 8 tool functions!\")\n",
    "else:\n",
    "    assistant = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eefdcd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing Clinical Assistant with Integrated De-identification\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test Clinical Assistant with Integrated De-identification\n",
    "print(\"üß™ Testing Clinical Assistant with Integrated De-identification\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sample clinical queries to test the system with all available tools\n",
    "sample_queries = [\n",
    "    \"What are this patient's current lab abnormalities and what do they suggest clinically?\",\n",
    "    \"Can you summarize this patient's medical conditions and current medications?\",\n",
    "    \"What procedures has this patient undergone and what was the care plan?\",\n",
    "    \"Does this patient have any allergies I should be aware of before prescribing?\",\n",
    "    \"What is this patient's vaccination status and immunization history?\",\n",
    "    \"What imaging studies have been performed and what were the findings?\",\n",
    "    \"Based on all available data, what is the comprehensive clinical picture?\",\n",
    "    \"Are there any drug interactions or contraindications based on current medications and allergies?\"\n",
    "]\n",
    "\n",
    "# Enhanced interactive testing function with de-identification options\n",
    "# updated to use IPython display for better formatting\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def test_query(query_text: str, patient_id: str = \"12345678\", apply_deidentification: bool = True):\n",
    "    \"\"\"\n",
    "    Test function for interactive querying with de-identification options\n",
    "    \n",
    "    Args:\n",
    "        query_text: The clinical question to ask\n",
    "        patient_id: Patient identifier (default: \"12345678\")\n",
    "        apply_deidentification: Whether to apply de-identification (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        Assistant response\n",
    "    \"\"\"\n",
    "    if not assistant:\n",
    "        return \"‚ùå Clinical Assistant not initialized. Please set your OpenAI API key.\"\n",
    "    \n",
    "    header_md = f\"\"\"\n",
    "### üîç Patient Query Test\n",
    "- **Patient ID**: `{patient_id}`\n",
    "- **Query**: *{query_text}*\n",
    "- **De-identification**: `{\"Enabled\" if apply_deidentification else \"Disabled\"}`\n",
    "\"\"\"\n",
    "\n",
    "    display(Markdown(header_md))\n",
    "    display(Markdown(\"---\"))\n",
    "    display(Markdown(\"### ü§ñ Assistant Response\"))\n",
    "\n",
    "    response = assistant.process_clinical_query(query_text, patient_id, apply_deidentification)\n",
    "    display(Markdown(f\"```\\n{response}\\n```\"))\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "13a13644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### üîç Patient Query Test\n",
       "- **Patient ID**: `1329b83e-ea69-d184-b4af-0d2a8e07896e`\n",
       "- **Query**: *Based on all available data, what is the comprehensive clinical picture?*\n",
       "- **De-identification**: `Enabled`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ü§ñ Assistant Response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing tool call: get_patient_observations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí Redaction complete. PHI has been removed from the clinical note.\n",
      "üìÑ Redacted note: Patient: [REDACTED], born [REDACTED] (SSN [REDACTED]), presented to [REDACTED] on‚ÄØ[REDACTED] at‚ÄØ[REDACTED] when she was‚ÄØ[REDACTED] years old. Dr.‚ÄØ[REDACTED], general practice, recorded her height at‚ÄØ[REDACTED]‚ÄØcm (code‚ÄØ[REDACTED]‚Äë2) during a vital‚Äësigns observation when she was‚ÄØ[REDACTED] years old. Her encounter class was [REDACTED] clinic (environment), with a base cost of‚ÄØ$160.75, total claim cost‚ÄØ$547.85, fully covered by payer coverage of‚ÄØ$547.85 under a coverage amount of‚ÄØ$673,780.87. [REDACTED], a [REDACTED] non‚ÄëHispanic female from [REDACTED], residing at‚ÄØ[REDACTED] (Towner County, FIPS‚ÄØ38095), has an income of‚ÄØ$63,061, healthcare expenses of‚ÄØ$127,546.31, driver‚Äôs license‚ÄØS99963354, and passport‚ÄØX23683209X.\n",
      "Executing tool call: get_patient_conditions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí Redaction complete. PHI has been removed from the clinical note.\n",
      "üìÑ Redacted note: Patient: [REDACTED], born on [REDACTED] in [REDACTED], white, non‚ÄëHispanic, female, presented to [REDACTED] on [REDACTED] for a medication review due at age [REDACTED]; she resides at [REDACTED] and holds driver‚Äôs license [REDACTED] and passport [REDACTED]. Dr. [REDACTED], a general practitioner, recorded the encounter as an outpatient check‚Äëup with a base cost of $96.45, a total claim of $1,257.75 fully covered by the payer, while her cumulative healthcare expenses amount to $127,546.31 against coverage of $673,780.87. The encounter was classified under SNOMED‚ÄëCT code 314529007 (Medication review due) and was documented as an outpatient encounter with a provider specialty of general practice. Follow‚Äëup was scheduled for a future date to review medication adherence and any new concerns.\n",
      "Executing tool call: get_patient_medications\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí Redaction complete. PHI has been removed from the clinical note.\n",
      "üìÑ Redacted note: Ms. [REDACTED] was born [REDACTED] (age 23 at the start of her medication), a white, non‚ÄëHispanic female from [REDACTED], North Dakota, presented for an outpatient check‚Äëup at [REDACTED] under the care of Dr. [REDACTED], general practice. She received Acetaminophen 300‚ÄØmg / Hydrocodone Bitartrate 5‚ÄØmg oral tablets (pharmacy code‚ÄØ856987) from [REDACTED] to [REDACTED], with three dispenses totalling $97.29 (base cost $32.43, fully covered by payer), and the encounter itself cost $96.45 (claim cost $1,053.14, fully covered). Her home address is [REDACTED], she resides in [REDACTED], and her SSN is [REDACTED], driver‚Äôs license S[REDACTED], passport X[REDACTED].  Overall, her healthcare expenses total $127,546.31 against coverage of $673,780.87, with an annual income of $63,061.\n",
      "Executing tool call: get_patient_careplans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí Redaction complete. PHI has been removed from the clinical note.\n",
      "üìÑ Redacted note: Ms. [REDACTED] was born on June‚ÄØ7‚ÄØ1999 (SSN‚ÄØ[REDACTED]) in Oakes, North Dakota, a 26‚Äëyear‚Äëold white female from Towner County Medical Center Inc in Cando, ND (523 O'Kon Orchard, 58324, lat‚ÄØ48.4746, lon‚ÄØ‚Äë99.2337) for an ambulatory encounter classified as ‚ÄúEncounter for symptom (procedure)‚Äù related to acute bronchitis, and she is receiving a respiratory therapy care plan that began on December‚ÄØ21,‚ÄØ2015 and concluded on July‚ÄØ25,‚ÄØ2016. The visit, overseen by Dr. [REDACTED], a general practitioner, had a total claim cost of $96.45 fully covered by her insurance, with healthcare coverage of $673,780.87 and personal income of $63,061, and the encounter incurred a base cost of $96.45, contributing to her cumulative healthcare expenses of $127,546.31. She holds a North Dakota driver‚Äôs license‚ÄØS99963354 and passport‚ÄØX23683209X, lives in Towner County (FIPS‚ÄØ38095), and is currently not married. The organization‚Äôs address is H\n",
      "Executing tool call: get_patient_procedures\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí Redaction complete. PHI has been removed from the clinical note.\n",
      "üìÑ Redacted note: Patient: [REDACTED], born [REDACTED] in [REDACTED], North Dakota (SSN: [REDACTED]), presented on [REDACTED] to [REDACTED] in [REDACTED] for a [REDACTED] procedure performed by [REDACTED], which began at [REDACTED:00:00:00] and concluded at [REDACTED:00:00:00]; she was [REDACTED] at the time and the encounter was an [REDACTED] procedure for an [REDACTED] disposition. The total claim cost was $18,541.61 with $14,833.29 covered by the payer, leaving $3,708.32 as the patient‚Äôs out‚Äëof‚Äëpocket expense. [REDACTED]‚Äôs address is [REDACTED], Towner County; she is [REDACTED], holds driver‚Äôs license [REDACTED] and passport [REDACTED], and her cumulative healthcare expenses total [REDACTED], covered by [REDACTED], with an annual income of [REDACTED].\n",
      "Executing tool call: get_patient_imaging_studies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí Redaction complete. PHI has been removed from the clinical note.\n",
      "üìÑ Redacted note: Ms. Yaeko Ming Kshlerin, born 06/07/1999 (SSN‚ÄØ[REDACTED], driver‚Äôs license‚ÄØ[REDACTED], passport‚ÄØ[REDACTED]), a 25‚Äëyear‚Äëold white non‚ÄëHispanic female from Oakes, North Dakota, presented to TOWNER‚ÄØCOUNTY‚ÄØMEDICAL‚ÄØCENTER‚ÄØINC in Cando, ND for an ambulatory check‚Äëup with referral for dental care. She underwent a digital intra‚Äëoral radiography (DX, SOP‚ÄØ1.2.840.10008.5.1.4.1.1.1.3) of the internal part of the mouth (body structure code‚ÄØ700016008, procedure code‚ÄØ241046008); the encounter cost was $96.45, totaling a claim cost of $3,193.25, of which $2,554.60 was covered by the payer. Ms. Kshlerin‚Äôs medical expenses amount to $127,546.31 with coverage of $673,780.87 and an income of $63,061; her residence is [REDACTED] (Towner County, FIPS‚ÄØ[REDACTED]). The visit was conducted by Dr. Shiloh Larson, general practice, and the encounter was classified as an ‚ÄúEncounter\n",
      "Executing tool call: get_patient_immunizations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîí Redaction complete. PHI has been removed from the clinical note.\n",
      "üìÑ Redacted note: Patient: [REDACTED], born on [REDACTED] (SSN: [REDACTED]), presented to [REDACTED] on [REDACTED] for a general wellness examination. Dr. [REDACTED] documented a routine physical, noting she received the Influenza seasonal injectable preservative free vaccine (code‚ÄØ140) at age‚ÄØ[REDACTED], and discussed her healthcare expenses of $127,546.31 against coverage of $673,780.87, with a current income of $63,061; she resides at [REDACTED], North Dakota, 58324. Follow‚Äëup is scheduled as needed; the total claim cost was $593.90, with $475.12 covered by her payer.\n",
      "Executing tool call: get_patient_allergies\n",
      "üîí Redaction complete. PHI has been removed from the clinical note.\n",
      "üìÑ Redacted note: Patient: [REDACTED], SSN: [REDACTED], born on [REDACTED] in [REDACTED], presented to [REDACTED] on [REDACTED] for an encounter for problem [REDACTED] related to [REDACTED] with moderate rhinoconjunctivitis and mild skin eruptions, and she is currently under the care of [REDACTED].  \n",
      "The visit was classified as [REDACTED], with a base encounter cost of $96.45 and a total claim cost of $483.55; payer coverage was [REDACTED], leaving her responsible for the full cost, while her total healthcare expenses amount to $127,546.31 against a coverage pool of $673,780.87, and her annual income is $63,061.  \n",
      "Ms. Kshlerin resides at [REDACTED], and is a white, non‚ÄëHispanic female with no recorded marital status.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Based on the available data for the patient with ID **1329b83e-ea69-d184-b4af-0d2a8e07896e**, here is a comprehensive clinical picture:\n",
       "\n",
       "### Patient Demographics\n",
       "- **Age**: 26 years old (born on June 7, 1999)\n",
       "- **Gender**: Female\n",
       "- **Ethnicity**: White, non-Hispanic\n",
       "- **Residence**: Towner County, North Dakota\n",
       "- **Income**: $63,061\n",
       "- **Healthcare Expenses**: $127,546.31 against coverage of $673,780.87\n",
       "\n",
       "### Clinical Encounters\n",
       "1. **General Wellness Examination**: \n",
       "   - Conducted for routine physical assessment.\n",
       "   - Received the Influenza seasonal injectable preservative-free vaccine.\n",
       "   - Total claim cost: $593.90, with $475.12 covered by insurance.\n",
       "\n",
       "2. **Medication Review**:\n",
       "   - Encounter classified as an outpatient check-up.\n",
       "   - Follow-up scheduled to review medication adherence and any new concerns.\n",
       "   - Total claim cost: $1,257.75, fully covered by the payer.\n",
       "\n",
       "3. **Respiratory Therapy**:\n",
       "   - Received care for acute bronchitis.\n",
       "   - Care plan initiated on December 21, 2015, and concluded on July 25, 2016.\n",
       "   - Encounter cost: $96.45, fully covered by insurance.\n",
       "\n",
       "4. **Dental Care Referral**:\n",
       "   - Underwent digital intra-oral radiography.\n",
       "   - Encounter cost: $96.45, with a total claim of $3,193.25, of which $2,554.60 was covered by the payer.\n",
       "\n",
       "5. **Symptom Encounter**:\n",
       "   - Presented with moderate rhinoconjunctivitis and mild skin eruptions.\n",
       "   - Encounter cost: $483.55, with the patient responsible for the full cost.\n",
       "\n",
       "### Medications\n",
       "- **Acetaminophen 300 mg / Hydrocodone Bitartrate 5 mg**: \n",
       "   - Prescribed for pain management.\n",
       "   - Total cost for medication: $97.29, fully covered by the payer.\n",
       "\n",
       "### Procedures\n",
       "- **Dental Imaging**: \n",
       "   - Digital intra-oral radiography performed as part of dental care.\n",
       "\n",
       "### Immunizations\n",
       "- **Influenza Vaccine**: \n",
       "   - Received as part of routine care.\n",
       "\n",
       "### Allergies\n",
       "- No specific allergy information was provided in the data.\n",
       "\n",
       "### Summary\n",
       "The patient is a 26-year-old white female with a history of respiratory issues (acute bronchitis) and current management for rhinoconjunctivitis. She has undergone various outpatient encounters, including routine wellness checks, medication reviews, and dental referrals. Her healthcare expenses are significant, but she has substantial insurance coverage. There are no recorded allergies, and she is currently on a pain management regimen involving acetaminophen and hydrocodone.\n",
       "\n",
       "### Limitations\n",
       "- Specific details regarding chronic conditions, allergies, and comprehensive medication history were not provided.\n",
       "- Further information on recent laboratory tests or imaging studies would enhance the clinical picture.\n",
       "\n",
       "If you have any specific questions or need further details, please let me know!\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Based on the available data for the patient with ID **1329b83e-ea69-d184-b4af-0d2a8e07896e**, here is a comprehensive clinical picture:\\n\\n### Patient Demographics\\n- **Age**: 26 years old (born on June 7, 1999)\\n- **Gender**: Female\\n- **Ethnicity**: White, non-Hispanic\\n- **Residence**: Towner County, North Dakota\\n- **Income**: $63,061\\n- **Healthcare Expenses**: $127,546.31 against coverage of $673,780.87\\n\\n### Clinical Encounters\\n1. **General Wellness Examination**: \\n   - Conducted for routine physical assessment.\\n   - Received the Influenza seasonal injectable preservative-free vaccine.\\n   - Total claim cost: $593.90, with $475.12 covered by insurance.\\n\\n2. **Medication Review**:\\n   - Encounter classified as an outpatient check-up.\\n   - Follow-up scheduled to review medication adherence and any new concerns.\\n   - Total claim cost: $1,257.75, fully covered by the payer.\\n\\n3. **Respiratory Therapy**:\\n   - Received care for acute bronchitis.\\n   - Care plan initiated on December 21, 2015, and concluded on July 25, 2016.\\n   - Encounter cost: $96.45, fully covered by insurance.\\n\\n4. **Dental Care Referral**:\\n   - Underwent digital intra-oral radiography.\\n   - Encounter cost: $96.45, with a total claim of $3,193.25, of which $2,554.60 was covered by the payer.\\n\\n5. **Symptom Encounter**:\\n   - Presented with moderate rhinoconjunctivitis and mild skin eruptions.\\n   - Encounter cost: $483.55, with the patient responsible for the full cost.\\n\\n### Medications\\n- **Acetaminophen 300 mg / Hydrocodone Bitartrate 5 mg**: \\n   - Prescribed for pain management.\\n   - Total cost for medication: $97.29, fully covered by the payer.\\n\\n### Procedures\\n- **Dental Imaging**: \\n   - Digital intra-oral radiography performed as part of dental care.\\n\\n### Immunizations\\n- **Influenza Vaccine**: \\n   - Received as part of routine care.\\n\\n### Allergies\\n- No specific allergy information was provided in the data.\\n\\n### Summary\\nThe patient is a 26-year-old white female with a history of respiratory issues (acute bronchitis) and current management for rhinoconjunctivitis. She has undergone various outpatient encounters, including routine wellness checks, medication reviews, and dental referrals. Her healthcare expenses are significant, but she has substantial insurance coverage. There are no recorded allergies, and she is currently on a pain management regimen involving acetaminophen and hydrocodone.\\n\\n### Limitations\\n- Specific details regarding chronic conditions, allergies, and comprehensive medication history were not provided.\\n- Further information on recent laboratory tests or imaging studies would enhance the clinical picture.\\n\\nIf you have any specific questions or need further details, please let me know!'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Test with a sample patient ID (this will be de-identified)\n",
    "test_patient_id = \"1329b83e-ea69-d184-b4af-0d2a8e07896e\"\n",
    "query = sample_queries[6]\n",
    "test_query(query, test_patient_id, apply_deidentification=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health-hw7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
